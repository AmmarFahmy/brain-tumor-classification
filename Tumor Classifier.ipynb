{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tumor Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom as pdc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import models\n",
    "import json\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to the MRI Scan of Whole Brain / First Plane of Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'source/PILO/Stanford/ST_PF-PILO_T2_Axial/no_roi/ST_PF-PILO_M_0046-01-IM-0786-0001.dcm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read the Brain MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_volume(img_path):\n",
    "    min_max = json.load(open(os.path.join('meta', 'clf_meta.json'), 'r'))\n",
    "    volume = None\n",
    "    \n",
    "    if img_path[-4:] == '.dcm':\n",
    "        volume = []\n",
    "        img_path = '-'.join(img_path.split('-')[:-1])\n",
    "        img_path = img_path.split(os.sep)\n",
    "        img_path, filename = '{}'.format(os.sep).join(img_path[:-1]), img_path[-1]\n",
    "        for _, _, files in os.walk(img_path):\n",
    "            files = sorted(filter(lambda x: x.startswith(filename), files))\n",
    "            for file in files:\n",
    "                data = pdc.dcmread(os.path.join(img_path, file))\n",
    "                volume.append(data.pixel_array.tolist())\n",
    "        volume = np.asarray(volume)\n",
    "    else:\n",
    "        volume = np.load(img_path)['T2 ax'].transpose((2,0,1))\n",
    "    \n",
    "    volume = (volume - volume.mean())/volume.std()\n",
    "    volume = 255 * (volume - min_max['min']) / (min_max['max'] - min_max['min'])\n",
    "    volume = np.clip(volume, 0, 255)\n",
    "    volume = np.rot90(volume, axes=(2,1))\n",
    "    return np.repeat(np.expand_dims(volume, axis=-1), 3, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to fetch Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(key, dropout_rate):\n",
    "    preprocess = None\n",
    "    model = None\n",
    "    model_d = {'densenet': 'dn121', 'inceptionresnet': 'irv2',\n",
    "               'inception': 'iv3', 'resnet': 'r50',\n",
    "               'vgg': 'vgg', 'xception': 'x'}\n",
    "    if key == 'densenet':\n",
    "        from models.densenet import get_classifier, get_preprocess\n",
    "    elif key == 'inceptionresnet':\n",
    "        from models.inceptionresnet import get_classifier, get_preprocess\n",
    "    elif key == 'inception':\n",
    "        from models.inception import get_classifier, get_preprocess\n",
    "    elif key == 'resnet':\n",
    "        from models.resnet import get_classifier, get_preprocess\n",
    "    elif key == 'vgg':\n",
    "        from models.vgg import get_classifier, get_preprocess\n",
    "    else:\n",
    "        from models.xception import get_classifier, get_preprocess\n",
    "\n",
    "    model_path = os.path.join('weights', 'clf_{}_{}.h5'.format(key, dropout_rate))\n",
    "    model = load_model(model_path)\n",
    "    model = Model(inputs=model.layers[0].input,\n",
    "                  outputs=model.layers[-2].output,\n",
    "                  name=key)\n",
    "    return (model, get_preprocess())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to fetch Paraclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_paraclassifier(key):\n",
    "    model = None\n",
    "    model_d = {'densenet': 'dn121', 'inceptionresnet': 'irv2',\n",
    "               'inception': 'iv3', 'resnet': 'r50',\n",
    "               'vgg': 'vgg', 'xception': 'x', 'ensemble': 'ensemble'}\n",
    "    if key == 'densenet':\n",
    "        from models.densenet import get_paraclassifier\n",
    "    elif key == 'inceptionresnet':\n",
    "        from models.inceptionresnet import get_paraclassifier\n",
    "    elif key == 'inception':\n",
    "        from models.inception import get_paraclassifier\n",
    "    elif key == 'resnet':\n",
    "        from models.resnet import get_paraclassifier\n",
    "    elif key == 'vgg':\n",
    "        from models.vgg import get_paraclassifier\n",
    "    else:\n",
    "        from models.xception import get_paraclassifier\n",
    "\n",
    "    model_path = os.path.join('weights', 'para_{}.h5'.format(key))\n",
    "    model = load_model(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result from Best Individual Model - DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: 'DIPG', 1: 'EP', 2: 'MB', 3: 'PILO', 4: 'Normal'}\n",
    "\n",
    "volume = load_volume(path)\n",
    "config = json.load(open(os.path.join('logs', 'clf_config.json'), 'r'))\n",
    "\n",
    "model, preprocess = build_classifier('densenet', config['densenet'])\n",
    "vector = model.predict(preprocess(volume))\n",
    "del model\n",
    "del preprocess\n",
    "_ = gc.collect()\n",
    "\n",
    "vector = np.expand_dims(vector, axis=0)\n",
    "model = build_paraclassifier('ensemble')\n",
    "prediction = model.predict(vector)\n",
    "\n",
    "del model\n",
    "_ = gc.collect()\n",
    "\n",
    "for x in prediction[0].argsort()[-3:][::-1]:\n",
    "    print('{} - {:.2f}%'.format(mapping[x], prediction[0, x] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result from Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: 'DIPG', 1: 'EP', 2: 'MB', 3: 'PILO', 4: 'Normal'}\n",
    "\n",
    "volume = load_volume(path)\n",
    "config = json.load(open(os.path.join('logs', 'clf_config.json'), 'r'))\n",
    "vectors = None\n",
    "\n",
    "for key in sorted(config.keys()):\n",
    "    print('Fetching vectors from {}'.format(key))\n",
    "    K.clear_session()\n",
    "    model, preprocess = build_classifier(key, config[key])\n",
    "    if vectors is None:\n",
    "        vectors = model.predict(preprocess(volume))\n",
    "    else:\n",
    "        vectors += model.predict(preprocess(volume))\n",
    "    del model\n",
    "    del preprocess\n",
    "    _ = gc.collect()\n",
    "\n",
    "    vectors /= len(config.keys())\n",
    "vectors = np.expand_dims(vectors, axis=0)\n",
    "\n",
    "model = build_paraclassifier('ensemble')\n",
    "prediction = model.predict(vectors)\n",
    "\n",
    "del model\n",
    "_ = gc.collect()\n",
    "\n",
    "print()\n",
    "for x in prediction[0].argsort()[-3:][::-1]:\n",
    "    print('{} - {:.2f}%'.format(mapping[x], prediction[0, x] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
