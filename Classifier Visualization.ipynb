{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Results from Classifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import ClassifierGenerator\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Directory if not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join('docs', 'classifier')\n",
    "if not os.path.exists(base_path):\n",
    "    os.mkdir(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from Tuning ResNet 50 based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = float('inf')\n",
    "min_val_resnet = ''\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.suptitle('Comparitive Performance of ResNet Models on various Dropouts', fontsize=20)\n",
    "fig.set_figwidth(21)\n",
    "fig.set_figheight(9)\n",
    "\n",
    "ax[0].set_title('Validation MSE Loss/Epoch', fontsize=15)\n",
    "ax[1].set_title('Training MSE Loss/Epoch', fontsize=15)\n",
    "\n",
    "df = pd.read_csv('logs/clf_resnet_0.1.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.1')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.1')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_resnet = 'logs/clf_resnet_0.1.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_resnet_0.2.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.2')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.2')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_resnet = 'logs/clf_resnet_0.2.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_resnet_0.3.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.3')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.3')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_resnet = 'logs/clf_resnet_0.3.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_resnet_0.4.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.4')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.4')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_resnet = 'logs/clf_resnet_0.4.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_resnet_0.5.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.5')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.5')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_resnet = 'logs/clf_resnet_0.5.csv'\n",
    "del df\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "gc.collect()\n",
    "plt.savefig(os.path.join(base_path, 'resnet.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](docs/classifier/resnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from Tuning Inception V3 based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = float('inf')\n",
    "min_val_inception = ''\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.suptitle('Comparitive Performance of Inception Models on various Dropouts', fontsize=20)\n",
    "fig.set_figwidth(21)\n",
    "fig.set_figheight(9)\n",
    "\n",
    "ax[0].set_title('Validation MSE Loss/Epoch', fontsize=15)\n",
    "ax[1].set_title('Training MSE Loss/Epoch', fontsize=15)\n",
    "\n",
    "df = pd.read_csv('logs/clf_inception_0.1.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.1')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.1')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inception = 'logs/clf_inception_0.1.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_inception_0.2.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.2')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.2')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inception = 'logs/clf_inception_0.2.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_inception_0.3.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.3')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.3')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inception = 'logs/clf_inception_0.3.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_inception_0.4.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.4')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.4')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inception = 'logs/clf_inception_0.4.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_inception_0.5.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.5')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.5')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inception = 'logs/clf_inception_0.5.csv'\n",
    "del df\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "gc.collect()\n",
    "plt.savefig(os.path.join(base_path, 'inception.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](docs/classifier/inception.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from Tuning InceptionResNet V2 based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = float('inf')\n",
    "min_val_inceptionresnet = ''\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.suptitle('Comparitive Performance of InceptionResnet Models on various Dropouts', fontsize=20)\n",
    "fig.set_figwidth(21)\n",
    "fig.set_figheight(9)\n",
    "\n",
    "ax[0].set_title('Validation MSE Loss/Epoch', fontsize=15)\n",
    "ax[1].set_title('Training MSE Loss/Epoch', fontsize=15)\n",
    "\n",
    "df = pd.read_csv('logs/clf_inceptionresnet_0.1.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.1')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.1')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inceptionresnet = 'logs/clf_inceptionresnet_0.1.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_inceptionresnet_0.2.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.2')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.2')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inceptionresnet = 'logs/clf_inceptionresnet_0.2.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_inceptionresnet_0.3.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.3')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.3')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inceptionresnet = 'logs/clf_inceptionresnet_0.3.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_inceptionresnet_0.4.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.4')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.4')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inceptionresnet = 'logs/clf_inceptionresnet_0.4.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_inceptionresnet_0.5.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.5')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.5')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_inceptionresnet = 'logs/clf_inceptionresnet_0.5.csv'\n",
    "del df\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "gc.collect()\n",
    "plt.savefig(os.path.join(base_path, 'inceptionresnet.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](docs/classifier/inceptionresnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from Tuning DenseNet 121 based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = float('inf')\n",
    "min_val_densenet = ''\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.suptitle('Comparitive Performance of DenseNet Models on various Dropouts', fontsize=20)\n",
    "fig.set_figwidth(21)\n",
    "fig.set_figheight(9)\n",
    "\n",
    "ax[0].set_title('Validation MSE Loss/Epoch', fontsize=15)\n",
    "ax[1].set_title('Training MSE Loss/Epoch', fontsize=15)\n",
    "\n",
    "df = pd.read_csv('logs/clf_densenet_0.1.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.1')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.1')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_densenet = 'logs/clf_densenet_0.1.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_densenet_0.2.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.2')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.2')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_densenet = 'logs/clf_densenet_0.2.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_densenet_0.3.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.3')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.3')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_densenet = 'logs/clf_densenet_0.3.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_densenet_0.4.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.4')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.4')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_densenet = 'logs/clf_densenet_0.4.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_densenet_0.5.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.5')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.5')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_densenet = 'logs/clf_densenet_0.5.csv'\n",
    "del df\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "gc.collect()\n",
    "plt.savefig(os.path.join(base_path, 'densenet.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](docs/classifier/densenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from Tuning Xception based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = float('inf')\n",
    "min_val_xception = ''\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.suptitle('Comparitive Performance of Xception Models on various Dropouts', fontsize=20)\n",
    "fig.set_figwidth(21)\n",
    "fig.set_figheight(9)\n",
    "\n",
    "ax[0].set_title('Validation MSE Loss/Epoch', fontsize=15)\n",
    "ax[1].set_title('Training MSE Loss/Epoch', fontsize=15)\n",
    "\n",
    "df = pd.read_csv('logs/clf_xception_0.1.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.1')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.1')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_xception = 'logs/clf_xception_0.1.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_xception_0.2.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.2')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.2')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_xception = 'logs/clf_xception_0.2.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_xception_0.3.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.3')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.3')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_xception = 'logs/clf_xception_0.3.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_xception_0.4.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.4')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.4')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_xception = 'logs/clf_xception_0.4.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_xception_0.5.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.5')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.5')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_xception = 'logs/clf_xception_0.5.csv'\n",
    "del df\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "gc.collect()\n",
    "plt.savefig(os.path.join(base_path, 'xception.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](docs/classifier/xception.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from Tuning VGG 19 based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = float('inf')\n",
    "min_val_vgg = ''\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.suptitle('Comparitive Performance of VGG Models on various Dropouts', fontsize=20)\n",
    "fig.set_figwidth(21)\n",
    "fig.set_figheight(9)\n",
    "\n",
    "ax[0].set_title('Validation MSE Loss/Epoch', fontsize=15)\n",
    "ax[1].set_title('Training MSE Loss/Epoch', fontsize=15)\n",
    "\n",
    "df = pd.read_csv('logs/clf_vgg_0.1.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.1')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.1')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_vgg = 'logs/clf_vgg_0.1.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_vgg_0.2.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.2')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.2')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_vgg = 'logs/clf_vgg_0.2.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_vgg_0.3.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.3')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.3')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_vgg = 'logs/clf_vgg_0.3.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_vgg_0.4.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.4')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.4')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_vgg = 'logs/clf_vgg_0.4.csv'\n",
    "del df\n",
    "\n",
    "df = pd.read_csv('logs/clf_vgg_0.5.csv')\n",
    "ax[0].plot(df['val_loss'], label='Dropout - 0.5')\n",
    "ax[1].plot(df['loss'], label='Dropout - 0.5')\n",
    "if df['val_loss'].min() < min_val:\n",
    "    min_val = df['val_loss'].min()\n",
    "    min_val_vgg = 'logs/clf_vgg_0.5.csv'\n",
    "del df\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "gc.collect()\n",
    "plt.savefig(os.path.join(base_path, 'vgg.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](docs/classifier/vgg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ResNet - {}'.format(min_val_resnet.split('_')[-1][:-4]))\n",
    "print('Inception - {}'.format(min_val_inception.split('_')[-1][:-4]))\n",
    "print('InceptionResNet - {}'.format(min_val_inceptionresnet.split('_')[-1][:-4]))\n",
    "print('DenseNet - {}'.format(min_val_densenet.split('_')[-1][:-4]))\n",
    "print('Xception - {}'.format(min_val_xception.split('_')[-1][:-4]))\n",
    "print('VGG - {}'.format(min_val_vgg.split('_')[-1][:-4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Dropout Rates\n",
    "\n",
    "- ResNet - `0.4`\n",
    "- Inception - `0.3`\n",
    "- InceptionResNet - `0.3`\n",
    "- DenseNet - `0.2`\n",
    "- Xception - `0.3`\n",
    "- VGG - `0.3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "test = pd.read_csv(os.path.join('meta', 'clf_test.csv')).values.tolist()\n",
    "meta_file = open(os.path.join('meta', 'clf_meta.json'), 'r')\n",
    "min_max = json.load(meta_file)\n",
    "img_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fetch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(key, dropout_rate):\n",
    "    preprocess = None\n",
    "    model = None\n",
    "    model_d = {'densenet': 'dn121', 'inceptionresnet': 'irv2',\n",
    "               'inception': 'iv3', 'resnet': 'r50',\n",
    "               'vgg': 'vgg', 'xception': 'x'}\n",
    "    if key == 'densenet':\n",
    "        from models.densenet import get_classifier, get_preprocess\n",
    "    elif key == 'inceptionresnet':\n",
    "        from models.inceptionresnet import get_classifier, get_preprocess\n",
    "    elif key == 'inception':\n",
    "        from models.inception import get_classifier, get_preprocess\n",
    "    elif key == 'resnet':\n",
    "        from models.resnet import get_classifier, get_preprocess\n",
    "    elif key == 'vgg':\n",
    "        from models.vgg import get_classifier, get_preprocess\n",
    "    else:\n",
    "        from models.xception import get_classifier, get_preprocess\n",
    "\n",
    "    model_path = os.path.join('weights', 'clf_{}_{}.h5'.format(key, dropout_rate))\n",
    "    model = load_model(model_path)\n",
    "    return (model, get_preprocess())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet with Dropout=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "df = pd.read_csv(min_val_resnet)\n",
    "result.append('resnet')\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['categorical_accuracy'])\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['val_categorical_accuracy'])\n",
    "del df\n",
    "\n",
    "K.clear_session()\n",
    "model, preprocess = build_classifier('resnet', 0.4)\n",
    "test_generator = ClassifierGenerator(preprocess, test, min_max, 48, img_size, True, False)\n",
    "pred = model.evaluate_generator(test_generator)\n",
    "result.append(pred[1])\n",
    "results.append(result)\n",
    "\n",
    "del model\n",
    "del preprocess\n",
    "del test_generator\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception with Dropout=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "df = pd.read_csv(min_val_inception)\n",
    "result.append('inception')\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['categorical_accuracy'])\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['val_categorical_accuracy'])\n",
    "del df\n",
    "\n",
    "K.clear_session()\n",
    "model, preprocess = build_classifier('inception', 0.3)\n",
    "test_generator = ClassifierGenerator(preprocess, test, min_max, 48, img_size, True, False)\n",
    "pred = model.evaluate_generator(test_generator)\n",
    "result.append(pred[1])\n",
    "results.append(result)\n",
    "\n",
    "del model\n",
    "del preprocess\n",
    "del test_generator\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNet with Dropout=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "df = pd.read_csv(min_val_inceptionresnet)\n",
    "result.append('inceptionresnet')\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['categorical_accuracy'])\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['val_categorical_accuracy'])\n",
    "del df\n",
    "\n",
    "K.clear_session()\n",
    "model, preprocess = build_classifier('inceptionresnet', 0.3)\n",
    "test_generator = ClassifierGenerator(preprocess, test, min_max, 48, img_size, True, False)\n",
    "pred = model.evaluate_generator(test_generator)\n",
    "result.append(pred[1])\n",
    "results.append(result)\n",
    "\n",
    "del model\n",
    "del preprocess\n",
    "del test_generator\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet with Dropout=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "df = pd.read_csv(min_val_densenet)\n",
    "result.append('densenet')\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['categorical_accuracy'])\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['val_categorical_accuracy'])\n",
    "del df\n",
    "\n",
    "K.clear_session()\n",
    "model, preprocess = build_classifier('densenet', 0.2)\n",
    "test_generator = ClassifierGenerator(preprocess, test, min_max, 48, img_size, True, False)\n",
    "pred = model.evaluate_generator(test_generator)\n",
    "result.append(pred[1])\n",
    "results.append(result)\n",
    "\n",
    "del model\n",
    "del preprocess\n",
    "del test_generator\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception with Dropout=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "df = pd.read_csv(min_val_xception)\n",
    "result.append('xception')\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['categorical_accuracy'])\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['val_categorical_accuracy'])\n",
    "del df\n",
    "\n",
    "K.clear_session()\n",
    "model, preprocess = build_classifier('xception', 0.3)\n",
    "test_generator = ClassifierGenerator(preprocess, test, min_max, 48, img_size, True, False)\n",
    "pred = model.evaluate_generator(test_generator)\n",
    "result.append(pred[1])\n",
    "results.append(result)\n",
    "\n",
    "del model\n",
    "del preprocess\n",
    "del test_generator\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG with Dropout=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "df = pd.read_csv(min_val_vgg)\n",
    "result.append('vgg')\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['categorical_accuracy'])\n",
    "result.append(df.loc[df['val_loss'].idxmin()]['val_categorical_accuracy'])\n",
    "del df\n",
    "\n",
    "K.clear_session()\n",
    "model, preprocess = build_classifier('vgg', 0.3)\n",
    "test_generator = ClassifierGenerator(preprocess, test, min_max, 48, img_size, True, False)\n",
    "pred = model.evaluate_generator(test_generator)\n",
    "result.append(pred[1])\n",
    "results.append(result)\n",
    "\n",
    "del model\n",
    "del preprocess\n",
    "del test_generator\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results, columns=['Name', 'Training Accuracy',\n",
    "                                                                     'Validation Accuracy',\n",
    "                                                                     'Test Accuracy'])\n",
    "print(df)\n",
    "df.to_csv(os.path.join('meta', 'clf_results.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
